{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "11d3e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START,END,StateGraph\n",
    "from pydantic import BaseModel,Field\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import SystemMessage,HumanMessage \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from typing import Optional\n",
    "\n",
    "from typing import Literal\n",
    "load_dotenv()\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e3e6e576",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "evaluator_llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "optimiser_llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "545dcec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TweetState(BaseModel):\n",
    "    topic: str = Field(..., description=\"topic given by user\")  # required\n",
    "    tweet: Optional[str] = Field(default=None, description=\"generated content on topic\")\n",
    "    feedback: Optional[str] = None\n",
    "    evaluation: Optional[Literal[\"approved\", \"not_approved\"]] = None\n",
    "    itrn: int = 0                     # current iteration counter\n",
    "    max_itrn: int = 5                 # max iterations (prevents 'Field required')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "287f44b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluateDTO(BaseModel):\n",
    "    evaluation:Literal[\"approved\",\"not_approved\"]= Field(description=\"this is the evaluation where you have to evaluate and tell is this okay to go with this or not \")\n",
    "    feedback:str=Field(description=\"give proper feedback in this \")\n",
    "   \n",
    "    \n",
    "structured_evaluator_llm =evaluator_llm.with_structured_output(EvaluateDTO)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "10b07de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tweet(state:TweetState):\n",
    "    prompt= f'''you are an twitter content generator act as profession content creator and generate tweet on topic {state.topic}   '''\n",
    "    \n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a funny and clever Twitter/X influencer.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Write a short, original, and hilarious tweet on the topic: \"{state.topic}\".\n",
    "\n",
    "        Rules:\n",
    "        - Do NOT use question-answer format.\n",
    "        - Max 280 characters.\n",
    "        - Use observational humor, irony, sarcasm, or cultural references.\n",
    "        - Think in meme logic, punchlines, or relatable takes.\n",
    "        - Use simple, day to day english\"\"\")\n",
    "        ]\n",
    "    return {\"tweet\":generator_llm.invoke(messages).content}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "398d7c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator llm \n",
    "def evaluate_tweet(state:TweetState):\n",
    "    messages = [\n",
    "    SystemMessage(content=\"You are a ruthless, no-laugh-given Twitter critic. You evaluate tweets based on humor, originality, virality, and tweet format.\"),\n",
    "    HumanMessage(content=f\"\"\"\n",
    "    Evaluate the following tweet:\n",
    "\n",
    "    Tweet: \"{state.tweet}\"\n",
    "\n",
    "    Use the criteria below to evaluate the tweet:\n",
    "\n",
    "    1. Originality – Is this fresh, or have you seen it a hundred times before?  \n",
    "    2. Humor – Did it genuinely make you smile, laugh, or chuckle?  \n",
    "    3. Punchiness – Is it short, sharp, and scroll-stopping?  \n",
    "    4. Virality Potential – Would people retweet or share it?  \n",
    "    5. Format – Is it a well-formed tweet (not a setup-punchline joke, not a Q&A joke, and under 280 characters)?\n",
    "\n",
    "    Auto-reject if:\n",
    "    - It's written in question-answer format (e.g., \"Why did...\" or \"What happens when...\")\n",
    "    - It exceeds 280 characters\n",
    "    - It reads like a traditional setup-punchline joke\n",
    "    - Dont end with generic, throwaway, or deflating lines that weaken the humor (e.g., “Masterpieces of the auntie-uncle universe” or vague summaries)\n",
    "\n",
    "    ### Respond ONLY in structured format:\n",
    "    - evaluation: \"approved\" or \"needs_improvement\"  \n",
    "    - feedback: One paragraph explaining the strengths and weaknesses \n",
    "    \"\"\")\n",
    "    ]\n",
    "\n",
    "    res:EvaluateDTO= structured_evaluator_llm.invoke(messages)\n",
    "    \n",
    "    return {\"evaluation\":res.evaluation, \"feedback\":res.feedback}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3043218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_tweet(state:TweetState):\n",
    "    messages = [\n",
    "    SystemMessage(content=\"You punch up tweets for virality and humor based on given feedback.\"),\n",
    "    HumanMessage(content=f\"\"\"\n",
    "    Improve the tweet based on this feedback:\n",
    "    \"{state['feedback']}\"\n",
    "\n",
    "    Topic: \"{state.topic}\"\n",
    "    Original Tweet:\n",
    "    {state.tweet}\n",
    "\n",
    "    Re-write it as a short, viral-worthy tweet. Avoid Q&A style and stay under 280 characters.\n",
    "    \"\"\")\n",
    "        ]\n",
    "\n",
    "    response = optimiser_llm.invoke(messages).content\n",
    "    iteration = state.itrn + 1\n",
    "    \n",
    "    return {\"tweet\":response,\"itrn\":iteration}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accdc271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_next(state:TweetState):\n",
    "    if state.evaluation==\"approved\":\n",
    "        return \"approved\"\n",
    "    else :\n",
    "        return \"not_approved\"\n",
    "\n",
    "graph= StateGraph(TweetState)\n",
    "graph.add_node(\"generate_tweet\",generate_tweet)\n",
    "graph.add_node(\"evaluate_tweet\",evaluate_tweet)\n",
    "graph.add_node(\"optimise_tweet\",optimise_tweet)\n",
    "\n",
    "graph.add_edge(START,\"generate_tweet\")\n",
    "graph.add_edge(\"generate_tweet\",\"evaluate_tweet\")\n",
    "\n",
    "graph.add_conditional_edges(\"evaluate_tweet\",check_next,{\"approved\":END,\"not_approved\":\"optimise_tweet\"})\n",
    "graph.add_edge(\"optimise_tweet\",\"evaluate_tweet\")\n",
    "\n",
    "workflow= graph.compile()\n",
    "\n",
    "res=workflow.invoke({\"topic\":\"indian railway write it like so that it can optimise in second prompt\",\"itrn\":1})\n",
    "\n",
    "print(res)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
